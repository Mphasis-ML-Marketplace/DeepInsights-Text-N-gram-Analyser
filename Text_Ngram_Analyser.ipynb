{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mphasis DeepInsights Text N-gram Analyser\n",
    "\n",
    "Text n-gram analyser finds meaningful and frequent n-grams in the provided text. An n-gram is a contiguous sequence of n terms from a given sample of text. Currently, this module provides bigrams, trigrams \n",
    "and four-grams with their corresponding number of frequent occurrences in the text. These meaningful n-grams are handy in various linguistic analysis solutions such as entity identification, document indexing, and topic modelling. Mphasis DeepInsights is a cloud-based cognitive computing platform that offers data extraction & predictive analytics capabilities.\n",
    "\n",
    "### Prerequisite\n",
    "\n",
    "To run this algorithm you need to have access to the following AWS Services:\n",
    "- Access to AWS SageMaker and the model package.\n",
    "- An S3 bucket to specify input/output.\n",
    "- Role for AWS SageMaker to access input/output from S3.\n",
    "\n",
    "This sample notebook shows you how to deploy Mphasis DeepInsights Text N-gram Analyser using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to Mphasis DeepInsights Text N-gram Analyser. If so, skip step: [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Output Result](#D.-Output-Result)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "3. [Perform batch inference](#3.-Perform-batch-inference) \n",
    "4. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page Mphasis DeepInsights Text N-gram Analyser\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn='arn:aws:sagemaker:us-east-2:786796469737:model-package/n-grams-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from zipfile import ZipFile\n",
    "import uuid\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-2-786796469737'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "bucket=sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='ngram-b'\n",
    "\n",
    "content_type='text/plain'\n",
    "\n",
    "real_time_inference_instance_type='ml.m5.large'\n",
    "batch_transform_inference_instance_type='ml.m5.large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.predictor.RealTimePredictor(endpoint, session,content_type)\n",
    "\n",
    "#create a deployable model from the model package.\n",
    "\n",
    "model = ModelPackage(role=role,\n",
    "                    model_package_arn=model_package_arn,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    predictor_cls=predict_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "\n",
    "## Input Data\n",
    "\n",
    "    1) The input file should be in “.txt” format with “utf-8” encoding.\n",
    "    2) The text should be written in English language.\n",
    "    3) The size of input text file should be less than 200 KB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'sample-input.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"ContentType\": \"text/csv; charset=utf-8\",\r\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint --endpoint-name $model_name --body fileb://$file_name --content-type 'text/plain' --region us-east-2 output.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Output Results\n",
    "\n",
    "1)\tThe output file (in csv format) contains the following columns:\n",
    "    \n",
    "    a.\tBigrams\n",
    "    b.\tFreq_bigram : Count of bigram (decreasing order)\n",
    "    c.\t3_grams\n",
    "    d.\tFreq_3gram : Count of 3_gram (decreasing order)\n",
    "    e.\t4_grams\n",
    "    f.\tFreq_4gram : Count of 4_gram (decreasing order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Freq_bigram</th>\n",
       "      <th>3_gram</th>\n",
       "      <th>Freq_3gram</th>\n",
       "      <th>4_gram</th>\n",
       "      <th>Freq_4gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>world cup</td>\n",
       "      <td>39.0</td>\n",
       "      <td>quality of life</td>\n",
       "      <td>27.0</td>\n",
       "      <td>player of the year</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>income countries</td>\n",
       "      <td>35.0</td>\n",
       "      <td>low income countries</td>\n",
       "      <td>15.0</td>\n",
       "      <td>value of the internet</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhyan chand</td>\n",
       "      <td>29.0</td>\n",
       "      <td>middle income countries</td>\n",
       "      <td>14.0</td>\n",
       "      <td>player of the tournament</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>life satisfaction</td>\n",
       "      <td>28.0</td>\n",
       "      <td>economist intelligence unit</td>\n",
       "      <td>8.0</td>\n",
       "      <td>quality of life index</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low income</td>\n",
       "      <td>28.0</td>\n",
       "      <td>rajiv gandhi khel</td>\n",
       "      <td>7.0</td>\n",
       "      <td>gap in financial inclusion</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Bigram  Freq_bigram                       3_gram  Freq_3gram  \\\n",
       "0          world cup         39.0              quality of life        27.0   \n",
       "1   income countries         35.0         low income countries        15.0   \n",
       "2        dhyan chand         29.0      middle income countries        14.0   \n",
       "3  life satisfaction         28.0  economist intelligence unit         8.0   \n",
       "4         low income         28.0            rajiv gandhi khel         7.0   \n",
       "\n",
       "                       4_gram  Freq_4gram  \n",
       "0          player of the year         7.0  \n",
       "1       value of the internet         7.0  \n",
       "2    player of the tournament         5.0  \n",
       "3       quality of life index         5.0  \n",
       "4  gap in financial inclusion         4.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.getcwd()\n",
    "file_name = 'output.csv'\n",
    "\n",
    "output_df = pd.read_csv(file_name)\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=sage.predictor.Predictor(model_name, sagemaker_session,content_type)\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together. If you are not familiar with batch transform, and want to learn more, see these links:\n",
    "1. [How it works](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html)\n",
    "2. [How to run a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-786796469737/ngram-b\n"
     ]
    }
   ],
   "source": [
    "#upload the batch-transform job input files to S3\n",
    "transform_input_folder = \"data/input/batch\"\n",
    "transform_input = sagemaker_session.upload_data(transform_input_folder, key_prefix=model_name) \n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the batch-transform job\n",
    "transformer = model.transformer(1, batch_transform_inference_instance_type)\n",
    "transformer.transform(transform_input, content_type=content_type)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-786796469737/n-grams-v2-2021-04-02-13-09-24-596'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output is available on following path\n",
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file loaded from bucket\n"
     ]
    }
   ],
   "source": [
    "s3_conn = boto3.client(\"s3\")\n",
    "bucket_name=\"sagemaker-us-east-2-786796469737\"\n",
    "with open('output2.csv', 'wb') as f:\n",
    "    s3_conn.download_fileobj(bucket_name, os.path.basename(transformer.output_path)+'/sample-input.txt.out', f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Freq_bigram</th>\n",
       "      <th>3_gram</th>\n",
       "      <th>Freq_3gram</th>\n",
       "      <th>4_gram</th>\n",
       "      <th>Freq_4gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>world cup</td>\n",
       "      <td>39.0</td>\n",
       "      <td>quality of life</td>\n",
       "      <td>27.0</td>\n",
       "      <td>player of the year</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>income countries</td>\n",
       "      <td>35.0</td>\n",
       "      <td>low income countries</td>\n",
       "      <td>15.0</td>\n",
       "      <td>value of the internet</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhyan chand</td>\n",
       "      <td>29.0</td>\n",
       "      <td>middle income countries</td>\n",
       "      <td>14.0</td>\n",
       "      <td>player of the tournament</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>life satisfaction</td>\n",
       "      <td>28.0</td>\n",
       "      <td>economist intelligence unit</td>\n",
       "      <td>8.0</td>\n",
       "      <td>quality of life index</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low income</td>\n",
       "      <td>28.0</td>\n",
       "      <td>rajiv gandhi khel</td>\n",
       "      <td>7.0</td>\n",
       "      <td>gap in financial inclusion</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Bigram  Freq_bigram                       3_gram  Freq_3gram  \\\n",
       "0          world cup         39.0              quality of life        27.0   \n",
       "1   income countries         35.0         low income countries        15.0   \n",
       "2        dhyan chand         29.0      middle income countries        14.0   \n",
       "3  life satisfaction         28.0  economist intelligence unit         8.0   \n",
       "4         low income         28.0            rajiv gandhi khel         7.0   \n",
       "\n",
       "                       4_gram  Freq_4gram  \n",
       "0          player of the year         7.0  \n",
       "1       value of the internet         7.0  \n",
       "2    player of the tournament         5.0  \n",
       "3       quality of life index         5.0  \n",
       "4  gap in financial inclusion         4.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.getcwd()\n",
    "file_name = 'output2.csv'\n",
    "\n",
    "output_df = pd.read_csv(file_name)\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
